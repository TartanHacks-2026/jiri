# Jiri ğŸ¤–

**Self-Improving AI Agent with Dynamic Tool Discovery**

An intelligent agent that **learns and evolves in real-time** by automatically discovering and adding new MCP (Model Context Protocol) tools as needed. Start with zero capabilities â€” Jiri builds its own toolkit on-demand by semantically searching for relevant servers, connecting them, and expanding its abilities with every query.

---

## ğŸŒŸ The Self-Improving Difference

Unlike traditional AI assistants with fixed capabilities, Jiri:

- **Starts with zero tools** â€” Lightweight and fast to initialize
- **Discovers tools at runtime** â€” Semantic search finds the right MCP server for any query
- **Chains tools automatically** â€” Seamlessly combines multiple tools for complex multi-step tasks
- **Builds its own toolkit** â€” Automatically connects to new capabilities as users ask questions
- **Remembers what works** â€” LRU cache keeps frequently-used tools loaded
- **Gets smarter over time** â€” Usage metrics learn which tools to preload on next startup
- **Handles failures gracefully** â€” Unhealthy servers get cooldowns, working servers persist

---

## ğŸ“ Two Implementations

This repository contains **two separate implementations** of Jiri's MCP architecture, side-by-side:

| | [Dedalus](./Dedalus/) | [LangChain](./LangChain/) |
|---|---|---|
| **Agent Framework** | [Dedalus Labs SDK](https://dedaluslabs.ai) | [LangGraph](https://langchain-ai.github.io/langgraph/) + [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters) |
| **LLM Provider** | Anthropic (Claude Haiku 4.5) via Dedalus | OpenAI (GPT-4.1-mini) via LangChain |
| **Embeddings** | Dedalus Embeddings API | OpenAI `text-embedding-3-small` |
| **MCP Transport** | Dedalus marketplace URLs | Direct HTTP/SSE/stdio connections |
| **Tool Discovery** | Dedalus marketplace semantic search | Local semantic search with OpenAI embeddings |
| **Custom MCP Servers** | â€” | âœ… (e.g. `servers/news_server.py` via stdio) |
| **API Key Required** | `DEDALUS_API_KEY` | `OPENAI_API_KEY` |

Both implementations share the **same core architecture**:

```
MCP/
â”œâ”€â”€ web_server.py           # FastAPI web UI with WebSocket
â”œâ”€â”€ static/index.html       # Chat interface
â””â”€â”€ router/
    â”œâ”€â”€ core.py             # SmartRouter orchestrator
    â”œâ”€â”€ registry.py         # Tool registry with semantic search
    â”œâ”€â”€ tool_cache.py       # LRU cache for active servers
    â”œâ”€â”€ health.py           # Server health tracking
    â”œâ”€â”€ metrics.py          # Usage analytics
    â”œâ”€â”€ history.py          # Conversation history
    â””â”€â”€ config.py           # Configuration
```

---

## ğŸš€ Quick Start

### Dedalus Implementation

```bash
cd Dedalus
cp .env.example .env
# Add DEDALUS_API_KEY to .env
uv sync
cd MCP && uv run python web_server.py
```

### LangChain Implementation

```bash
cd LangChain
cp .env.example .env
# Add OPENAI_API_KEY to .env
uv sync
cd MCP && uv run python web_server.py
```

Then open: **http://localhost:8080**

---

## ğŸ¯ How It Works

### Runtime Tool Discovery

Jiri doesn't come pre-configured with tools. It **discovers capabilities dynamically** based on what you need:

```
You: How is MSFT stock doing?

1. Router checks cache â†’ No stock server found
2. Semantic search discovers a finance MCP server
3. Connects and executes stock lookup
4. Returns real-time MSFT data âœ…

Cache now contains: [finance-mcp]
```

### The Self-Improving Cycle

```
First Session (Cold Start):
  Query 1: "MSFT stock"      â†’ Discovers finance tool â†’ 3s
  Query 2: "AAPL stock"      â†’ Uses cached tool       â†’ 1s âš¡
  Query 3: "Send email"      â†’ Discovers email tool   â†’ 3s

Second Session (Learned Preferences):
  Startup: Preloads finance (most used) â† AUTOMATIC!
  Query 1: "TSLA stock"      â†’ Uses preloaded tool    â†’ 1s âš¡
```

### Automatic Tool Chaining

```
You: Explain the TensorFlow GitHub repo and email the summary to my team

1. Discovers Deep Wiki tool â†’ Analyzes repository
2. Discovers Gmail tool â†’ Sends summary email
âœ… Multi-tool workflow from a single natural language request!
```

---

## âœ¨ Core Features

- ğŸ§  **Runtime Tool Discovery** â€” Zero configuration, discovers MCP servers on-demand
- ğŸ”— **Automatic Tool Chaining** â€” Chains multiple tools for complex multi-step tasks
- ğŸ”„ **Continuous Learning** â€” Usage patterns shape which tools get preloaded
- ğŸ—„ï¸ **LRU Caching** â€” Keeps frequently-used tools loaded for instant reuse
- â¤ï¸â€ğŸ©¹ **Adaptive Health** â€” Failed servers get cooldowns, system self-heals
- ğŸ¨ **Beautiful Web UI** â€” Real-time chat with live logging and cache visualization
- ğŸ“Š **Live Observability** â€” Watch tool discovery, cache updates, and execution in real-time

---

## ğŸ—ï¸ Architecture

```
User Query
    â†“
SmartRouter.handle_turn()
    â†“
Check cache for matching tools
    â†“
If not found â†’ discover_tools() â†’ Semantic search â†’ Add to cache
    â†“
Execute tool via MCP server
    â†“
Post-run: LRU touch, metrics, health tracking
    â†“
Return response to user
```

**Components:**

| Component | Description |
|---|---|
| **SmartRouter** | Main orchestrator â€” manages discovery, caching, and execution |
| **ToolRegistry** | Semantic search over MCP registry using embeddings |
| **ToolCache** | LRU cache for active MCP server connections |
| **HealthTracker** | Server failure tracking with automatic cooldowns |
| **UsageMetrics** | Persistent usage analytics for smart preloading |
| **ConversationHistory** | Multi-turn dialogue context with rollback support |

---

## ğŸ“– More Details

- **[Dedalus README](./Dedalus/README.md)** â€” Setup, configuration, and usage for the Dedalus Labs implementation
- **[LangChain README](./LangChain/README.md)** â€” Setup, configuration, and usage for the LangChain/LangGraph implementation

---

## ğŸ”’ Security

- API keys stored in `.env` (gitignored)
- No credentials in logs or agent context
- WebSocket connections are local only

---

## ğŸ“„ License

MIT

---

**Built with â¤ï¸ for TartanHacks 2026**
